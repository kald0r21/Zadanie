{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b13076-4006-46e8-91f5-64f605afd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed7103e-a0ab-42dd-8bf5-005a2f8793f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawienia\n",
    "JSON_PATH = \"dataset/label.json\"\n",
    "VIDEO_PATH = \"dataset/traffic.mp4\"\n",
    "OUTPUT_VIDEO = \"dataset/result.mp4\"\n",
    "OUTPUT_CSV = \"dataset/results.csv\"\n",
    "LINE_Y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5ab7ca-62da-41fb-ae05-1576cfba467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottomCenterTracker:\n",
    "    def __init__(self, max_distance: int = 80, ttl: int = 20):\n",
    "        self.objects   = {}\n",
    "        self.ttl_map   = {}\n",
    "        self.next_id   = 0\n",
    "        self.max_dist  = max_distance\n",
    "        self.ttl       = ttl\n",
    "        self.crossed   = set()\n",
    "        self.prev_cy   = {}\n",
    "\n",
    "    def _match(self, centers):\n",
    "        ids   = list(self.objects.keys())\n",
    "        match = [-1] * len(centers)\n",
    "\n",
    "        for i, c in enumerate(centers):\n",
    "            best_id, best_d = None, self.max_dist + 1\n",
    "            for obj_id in ids:\n",
    "                d = np.linalg.norm(np.array(c) - np.array(self.objects[obj_id]))\n",
    "                if d < best_d:\n",
    "                    best_id, best_d = obj_id, d\n",
    "            if best_id is not None:\n",
    "                match[i] = best_id\n",
    "                ids.remove(best_id)\n",
    "        return match\n",
    "\n",
    "    def update(self, detections):\n",
    "\n",
    "        bottom_centers = [((x1 + x2)//2, y2) for (_, x1, y1, x2, y2) in detections]\n",
    "        matched        = self._match(bottom_centers)\n",
    "        updated        = []\n",
    "\n",
    "        for i, center in enumerate(bottom_centers):\n",
    "            obj_id = matched[i]\n",
    "            if obj_id == -1:\n",
    "                obj_id = self.next_id\n",
    "                self.next_id += 1\n",
    "            self.objects[obj_id] = center\n",
    "            self.ttl_map[obj_id] = 0\n",
    "            matched[i] = obj_id\n",
    "\n",
    "        for obj_id in list(self.ttl_map.keys()):\n",
    "            self.ttl_map[obj_id] += 1\n",
    "            if self.ttl_map[obj_id] > self.ttl:\n",
    "                self.objects.pop(obj_id, None)\n",
    "                self.ttl_map.pop(obj_id, None)\n",
    "                self.prev_cy.pop(obj_id, None)\n",
    "\n",
    "        for i, (cls, x1, y1, x2, y2) in enumerate(detections):\n",
    "            obj_id = matched[i]\n",
    "            _, cy  = bottom_centers[i]\n",
    "            prev_y = self.prev_cy.get(obj_id)\n",
    "            crossed = False\n",
    "\n",
    "            if prev_y is not None:\n",
    "                if (prev_y < LINE_Y <= cy) or (prev_y > LINE_Y >= cy):\n",
    "                    if obj_id not in self.crossed:\n",
    "                        crossed = True\n",
    "                        self.crossed.add(obj_id)\n",
    "\n",
    "            self.prev_cy[obj_id] = cy\n",
    "            updated.append((obj_id, cls, x1, y1, x2, y2, crossed))\n",
    "\n",
    "        return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adcfafcb-b934-4ff5-9851-23ceee3257f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NOWA WERSJA interpolate_annotations_adjusted ---------------------------\n",
    "def interpolate_annotations_adjusted(json_path: str,\n",
    "                                     width: int,\n",
    "                                     height: int\n",
    ") -> Dict[int, List[Tuple[str, int, int, int, int]]]:\n",
    "    \"\"\"\n",
    "    Ładuje Label Studio JSON i zwraca:\n",
    "        { frame_idx (0‑based) : [(label, x1, y1, x2, y2), ...] }\n",
    "    * Obsługuje wartości zarówno 0‑1, jak i 0‑100 %.\n",
    "    * Koryguje klatkę (LS startuje od 1 → OpenCV od 0).\n",
    "    * Opcjonalnie cofa bbox o ~10 % w X i 20 % w Y, żeby\n",
    "      bottom‑center lepiej trafiał w tylny zderzak.\n",
    "    * Wypełnia dziury liniową interpolacją.\n",
    "    \"\"\"\n",
    "\n",
    "    def to_px(pct_or_frac: float, dim: int) -> int:\n",
    "        \"\"\"Zamienia 0‑1 lub 0‑100 % na px, zaokrąglając do int.\"\"\"\n",
    "        frac = pct_or_frac if pct_or_frac <= 1 else pct_or_frac / 100.0\n",
    "        return int(round(frac * dim))\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    annotations: Dict[int, List[Tuple[str, int, int, int, int]]] = {}\n",
    "\n",
    "    for item in data:\n",
    "        for ann in item.get(\"annotations\", []):\n",
    "            for result in ann.get(\"result\", []):\n",
    "                label     = result.get(\"value\", {}).get(\"labels\", [\"car\"])[0]\n",
    "                sequence  = result.get(\"value\", {}).get(\"sequence\", [])\n",
    "                prev_f, prev_box = None, None\n",
    "\n",
    "                for entry in sequence:\n",
    "                    if not entry.get(\"enabled\", True):\n",
    "                        continue\n",
    "\n",
    "                    frame = entry[\"frame\"] - 1          # 0‑based!\n",
    "                    x     = to_px(entry[\"x\"],      width)\n",
    "                    y     = to_px(entry[\"y\"],      height)\n",
    "                    w     = to_px(entry[\"width\"],  width)\n",
    "                    h     = to_px(entry[\"height\"], height)\n",
    "\n",
    "                    # lekkie przesunięcie bbox‑a “w tył”\n",
    "                    x -= int(0.10 * w)\n",
    "                    y -= int(0.20 * h)\n",
    "\n",
    "                    x1, y1 = x, y\n",
    "                    x2, y2 = x + w, y + h\n",
    "                    box    = (label, x1, y1, x2, y2)\n",
    "\n",
    "                    # interpolacja brakujących klatek\n",
    "                    if prev_f is not None and frame > prev_f + 1:\n",
    "                        gap = frame - prev_f\n",
    "                        for g in range(1, gap):\n",
    "                            alpha = g / gap\n",
    "                            interp = (\n",
    "                                label,\n",
    "                                int(prev_box[1] * (1 - alpha) + x1 * alpha),\n",
    "                                int(prev_box[2] * (1 - alpha) + y1 * alpha),\n",
    "                                int(prev_box[3] * (1 - alpha) + x2 * alpha),\n",
    "                                int(prev_box[4] * (1 - alpha) + y2 * alpha),\n",
    "                            )\n",
    "                            annotations.setdefault(prev_f + g, []).append(interp)\n",
    "\n",
    "                    annotations.setdefault(frame, []).append(box)\n",
    "                    prev_f, prev_box = frame, box\n",
    "\n",
    "    return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d450def6-b3f9-4b93-a8d3-1e7d0cfb2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    annotations = interpolate_annotations_adjusted(JSON_PATH, width, height)\n",
    "    tracker = BottomCenterTracker()\n",
    "\n",
    "    out = cv2.VideoWriter(OUTPUT_VIDEO, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (width, height))\n",
    "    results = []\n",
    "    frame_idx = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        cv2.line(frame, (0, LINE_Y), (width, LINE_Y), (0, 0, 255), 1)\n",
    "\n",
    "        detections = annotations.get(frame_idx, [])\n",
    "        tracked = tracker.update(detections)\n",
    "\n",
    "        for obj_id, cls, x1, y1, x2, y2, crossed in tracked:\n",
    "            color = (0, 255, 0) if not crossed else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f\"{cls}-{obj_id}\", (x1, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            results.append((frame_idx, obj_id, cls, x1, y1, x2, y2, crossed))\n",
    "\n",
    "\n",
    "        cv2.putText(frame, f\"Przekroczylo linie: {len(tracker.crossed)}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "    df = pd.DataFrame(results, columns=[\"frame\", \"id\", \"class\", \"x1\", \"y1\", \"x2\", \"y2\", \"crossed\"])\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f90f7-51d4-4fae-ab4f-79eabfffaa24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
